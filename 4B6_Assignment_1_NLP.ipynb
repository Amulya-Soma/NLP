{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4B6_Assignment-1_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amulya-Soma/NLP/blob/main/4B6_Assignment_1_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Tokenizing given paragraph into sentences\n"
      ],
      "metadata": {
        "id": "R0ATuIKG09ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "#Intializing the tokenizer with variable called tokens\n",
        "tokens = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "\n",
        "#Data to be tokenized is stored in variable called paragraph\n",
        "paragraph = \"Are you fascinated by the amount of text data available on the internet? Are you looking for ways to work with this text data but aren’t sure where to begin? Machines, after all, recognize numbers, not the letters of our language. And that can be a tricky landscape to navigate in machine learning. Solving an NLP problem is a multi-stage process. We need to clean the unstructured text data first before we can even think about getting to the modelling stage. Cleaning the data consists of a few key steps.\"\n",
        "\n",
        "#Tokenizing the paragraph into sentences\n",
        "print(tokens.tokenize(paragraph))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIZv22aN1ASi",
        "outputId": "38102955-37a1-4186-89fb-1530c57b06ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Are you fascinated by the amount of text data available on the internet?', 'Are you looking for ways to work with this text data but aren’t sure where to begin?', 'Machines, after all, recognize numbers, not the letters of our language.', 'And that can be a tricky landscape to navigate in machine learning.', 'Solving an NLP problem is a multi-stage process.', 'We need to clean the unstructured text data first before we can even think about getting to the modelling stage.', 'Cleaning the data consists of a few key steps.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Tokenizing given paragraph into words"
      ],
      "metadata": {
        "id": "ODRCySYC1ynT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenizing the same paragraph into words\n",
        "print(nltk.tokenize.word_tokenize(paragraph))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LT7yB5s13iO",
        "outputId": "638d456d-9f7d-4e71-b2e0-7a742b21a97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Are', 'you', 'fascinated', 'by', 'the', 'amount', 'of', 'text', 'data', 'available', 'on', 'the', 'internet', '?', 'Are', 'you', 'looking', 'for', 'ways', 'to', 'work', 'with', 'this', 'text', 'data', 'but', 'aren', '’', 't', 'sure', 'where', 'to', 'begin', '?', 'Machines', ',', 'after', 'all', ',', 'recognize', 'numbers', ',', 'not', 'the', 'letters', 'of', 'our', 'language', '.', 'And', 'that', 'can', 'be', 'a', 'tricky', 'landscape', 'to', 'navigate', 'in', 'machine', 'learning', '.', 'Solving', 'an', 'NLP', 'problem', 'is', 'a', 'multi-stage', 'process', '.', 'We', 'need', 'to', 'clean', 'the', 'unstructured', 'text', 'data', 'first', 'before', 'we', 'can', 'even', 'think', 'about', 'getting', 'to', 'the', 'modelling', 'stage', '.', 'Cleaning', 'the', 'data', 'consists', 'of', 'a', 'few', 'key', 'steps', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Stem and Lemma words for given words"
      ],
      "metadata": {
        "id": "LelzV_o55iDr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Stem words***"
      ],
      "metadata": {
        "id": "Dx6HfFYOBS1t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "#Stemming the given words and printing\n",
        "print(ps.stem(\"cats\"))\n",
        "print(ps.stem(\"trouble\"))\n",
        "print(ps.stem(\"troubling\"))\n",
        "print(ps.stem(\"troubled\"))\n",
        "print(ps.stem(\"having\"))\n",
        "print(ps.stem(\"Corriendo\"))\n",
        "print(ps.stem(\"at\"))\n",
        "print(ps.stem(\"was\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6v92VJO3fCz",
        "outputId": "2f58e607-2fc4-48b3-808b-342f53f25793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n",
            "troubl\n",
            "troubl\n",
            "troubl\n",
            "have\n",
            "corriendo\n",
            "at\n",
            "wa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Lemma words***"
      ],
      "metadata": {
        "id": "CkHfQpxi5T4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "lm = WordNetLemmatizer()\n",
        "\n",
        "#Lemmatizing the given words and printing\n",
        "print(lm.lemmatize(\"cats\"))\n",
        "print(lm.lemmatize(\"trouble\"))\n",
        "print(lm.lemmatize(\"troubling\"))\n",
        "print(lm.lemmatize(\"troubled\"))\n",
        "print(lm.lemmatize(\"having\"))\n",
        "print(lm.lemmatize(\"Corriendo\"))\n",
        "print(lm.lemmatize(\"at\"))\n",
        "print(lm.lemmatize(\"was\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPn7Dl_B4TMm",
        "outputId": "1b6b4c63-f722-4d58-aeb4-b682743d7d43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n",
            "trouble\n",
            "troubling\n",
            "troubled\n",
            "having\n",
            "Corriendo\n",
            "at\n",
            "wa\n"
          ]
        }
      ]
    }
  ]
}